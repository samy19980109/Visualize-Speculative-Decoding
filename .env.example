# === Required ===
CEREBRAS_API_KEY=your-cerebras-api-key-here

# Target model running on Cerebras Cloud (REQUIRED - no default)
# Available options (check https://inference.cerebras.ai for current list):
#   llama3.1-8b
#   llama-3.3-70b
#   qwen-3-32b
CEREBRAS_TARGET_MODEL=llama-3.3-70b

# === Optional ===
# Draft model running locally via MLX-LM
# DRAFT_MODEL=mlx-community/Llama-3.2-3B-Instruct-4bit

# Number of tokens to draft per round (1-16)
# SPECULATION_K=8

# Sampling temperature for draft model
# TEMPERATURE=0.7

# Maximum tokens to generate total
# MAX_TOKENS=512
