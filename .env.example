# === Required ===
CEREBRAS_API_KEY=your-cerebras-api-key-here

# Target model running on Cerebras Cloud (REQUIRED - no default)
# Available options (check https://inference.cerebras.ai for current list):
#   gpt-oss-120b
#   qwen-3-32b
CEREBRAS_TARGET_MODEL=gpt-oss-120b

# === Optional ===
# Draft model running locally via MLX-LM
# DRAFT_MODEL=mlx-community/Llama-3.2-3B-Instruct-4bit

# Number of tokens to draft per round (1-16)
# SPECULATION_K=8

# Sampling temperature for draft model
# TEMPERATURE=0.7

# Maximum tokens to generate total
# MAX_TOKENS=512
